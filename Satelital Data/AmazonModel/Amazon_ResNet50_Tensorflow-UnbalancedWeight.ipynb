{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b15880c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981cf53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to file (for Colab)\n",
    "PATH = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76776fb",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "<a href=\"https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/data\">Amazon Dataset</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b83afc9",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a014ad7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-jpg\n",
      "train-jpg\n",
      "the max width is: 256, and the min width is: 256\n",
      "the max height is: 256, and the min height is: 256\n",
      "the mean width is: 256.0, and the mean height is: 256.0\n"
     ]
    }
   ],
   "source": [
    "# See the shape of all images:\n",
    "# Main Directory\n",
    "main_path = PATH + 'AmazonDataset/'\n",
    "\n",
    "\n",
    "def get_size(folder):\n",
    "    sizes = []\n",
    "    # Get from main directory all sub-directories\n",
    "    for folder_path in os.listdir(folder):\n",
    "        # Skip\n",
    "        if (folder_path == '.DS_Store'):\n",
    "            continue\n",
    "        # See Train and Test sub-directories\n",
    "        for folder_name in os.listdir(os.path.join(folder, folder_path)):\n",
    "            # Skip\n",
    "            if (folder_name in ['.DS_Store', 'test_v2_file_mapping.csv', 'train_v2.csv']):\n",
    "                continue\n",
    "            print(folder_name)\n",
    "            for filename in os.listdir(os.path.join(folder, folder_path, folder_name)):\n",
    "                \n",
    "                # take image\n",
    "                img = Image.open(os.path.join(folder, folder_path, folder_name, filename))\n",
    "                # Get image with \n",
    "                #print(img.size)\n",
    "                # Stores data like: (width, height)\n",
    "                sizes.append(img.size)\n",
    "            \n",
    "    print(f'the max width is: {max(sizes[0])}, and the min width is: {min(sizes[0])}')\n",
    "    print(f'the max height is: {max(sizes[1])}, and the min height is: {min(sizes[1])}')\n",
    "    print(f'the mean width is: {np.mean(sizes[0])}, and the mean height is: {np.mean(sizes[1])}')\n",
    "\n",
    "# Call the function\n",
    "get_size(main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c218b40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = PATH + 'AmazonDataset/Train/'\n",
    "test_path = PATH + 'AmazonDataset/Test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafd482a",
   "metadata": {},
   "source": [
    "## See Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8004cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_folder_train = train_path + '/train-jpg/'\n",
    "images_folder_test = test_path + '/test-jpg/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de194608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_images(axis=(2,2), images_folder_path=images_folder_train, train = True):\n",
    "    \n",
    "    if train:\n",
    "        train = 'train_'\n",
    "    else:\n",
    "        train = 'test_'\n",
    "        \n",
    "    # Grid\n",
    "    f, axarr = plt.subplots(axis[0], axis[1], figsize=(30/axis[1], 10))\n",
    "    \n",
    "    for i in range(0,axis[0]):\n",
    "        for j in range (0,axis[1]):\n",
    "            # Choose a random image\n",
    "            index_img = np.random.randint(100)\n",
    "            filename = images_folder_path + train + str(index_img) + '.jpg'\n",
    "            # Read Image:\n",
    "            img = Image.open(filename).convert('RGB')\n",
    "            # To numpy\n",
    "            img = np.asarray(img)\n",
    "            # Plot\n",
    "            axarr[i,j].imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae36896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(axis=(3,3), images_folder_path=images_folder_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17060b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(axis=(3,3), images_folder_path=images_folder_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0c889d",
   "metadata": {},
   "source": [
    "## See Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed3a1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_labels = train_path + 'train_v2.csv'\n",
    "test_path_labels = test_path + 'test_v2_file_mapping.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7c885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Images and labels\n",
    "train_map = pd.read_csv(train_path_labels)\n",
    "train_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fc7af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(test_path_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ef3581",
   "metadata": {},
   "source": [
    "# Create Dataset\n",
    "* This is a multi labels task, so we need binary encode the tags\n",
    "* We don't have labels for testing images so we need to split data of train in train and test\n",
    "* We have many information so we need a data loader to wrap-up the data and avoid overload the GPU or RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77d707d",
   "metadata": {},
   "source": [
    "## Binary Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86da5244",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_encode = train_map.tags.str.get_dummies(sep=' ').columns\n",
    "tags_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08abacfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Tags\n",
    "list_tags = ['agriculture', 'bare_ground', 'cultivation', 'habitation', 'primary', 'road', 'water']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ce73b1",
   "metadata": {},
   "source": [
    "## Filter images with tags \n",
    "* We have many tags, but we just want images with tags in list_tags so we filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52c6623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_item(tag_string):\n",
    "    res = any(tag in tag_string for tag in list_tags)\n",
    "    return res    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10ba6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_map = train_map[train_map.tags.apply(lambda tag_string: filter_item(tag_string))]\n",
    "train_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cbe4fb",
   "metadata": {},
   "source": [
    "## Binary Encode and desired columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a989603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Encode\n",
    "encode = train_map.tags.str.get_dummies(sep=' ')\n",
    "train_map = pd.concat([train_map, encode], axis=1)\n",
    "train_map.drop(columns=[\"tags\"], inplace=True)\n",
    "list_tags.insert(0,'image_name')\n",
    "train_map = train_map[list_tags]\n",
    "list_tags.pop(0)\n",
    "train_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca406a7",
   "metadata": {},
   "source": [
    "### Add \".jpg\" to image name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63abfc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_map.image_name = train_map.image_name.apply(lambda name: name + '.jpg')\n",
    "train_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d41d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in list_tags:\n",
    "    print(f'the images with {item} are {len(train_map[train_map[item] == 1])}')\n",
    "\n",
    "train_map[list_tags].sum().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a65cbc2",
   "metadata": {},
   "source": [
    "# Train, Test, Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868d81c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split Train and test\n",
    "train, test = train_test_split(train_map, test_size=0.2, random_state=1)\n",
    "\n",
    "# Split Train and validation\n",
    "train, validation = train_test_split(train_map, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdad3462",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e68ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9401a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4e7411",
   "metadata": {},
   "source": [
    "# Creating data Generator and Data Agumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb54270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# We can't load all data in memory at once, so we use a DataGenerator\n",
    "#Create instance of ImageDataGenerator Class\n",
    "image_gen_train = ImageDataGenerator(\n",
    "                    # Rescale\n",
    "                    rescale=1./255,\n",
    "                    # Rotate 30\n",
    "                    rotation_range=30,\n",
    "                    # Shift pixel values\n",
    "                    width_shift_range=.15,\n",
    "                    height_shift_range=.15,\n",
    "                    # Flip all image\n",
    "                    horizontal_flip=True,\n",
    "                    # Random zoom\n",
    "                    zoom_range=0.4\n",
    "                    )\n",
    "image_gen_test = ImageDataGenerator(rescale=1./255)\n",
    "image_gen_valid = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109d431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 256 # width = height\n",
    "batch_size = 32\n",
    "\n",
    "# Custom datagenerator\n",
    "train_datagen = image_gen_train.flow_from_dataframe(dataframe=train,\n",
    "                                                    directory=images_folder_train,\n",
    "                                                    x_col='image_name',\n",
    "                                                    y_col=list_tags,\n",
    "                                                    batch_size=batch_size, #16,32,64...\n",
    "                                                    seed=1,\n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode=\"raw\",\n",
    "                                                    target_size=(width,width))\n",
    "                                                                \n",
    "test_datagen = image_gen_test.flow_from_dataframe(dataframe=test,\n",
    "                                                    directory=images_folder_train,\n",
    "                                                    x_col='image_name',\n",
    "                                                    y_col=list_tags,\n",
    "                                                    batch_size=batch_size, #16,32,64...\n",
    "                                                    seed=1,\n",
    "                                                    shuffle=False,\n",
    "                                                    class_mode=\"raw\",\n",
    "                                                    target_size=(width,width))\n",
    "\n",
    "valid_datagen = image_gen_valid.flow_from_dataframe(dataframe=validation,\n",
    "                                                    directory=images_folder_train,\n",
    "                                                    x_col='image_name',\n",
    "                                                    y_col=list_tags,\n",
    "                                                    batch_size=batch_size, #16,32,64...\n",
    "                                                    seed=1,\n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode=\"raw\",\n",
    "                                                    target_size=(width,width))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d37c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_images_datagen(axis=(2,2), images=None):\n",
    "\n",
    "    # Grid\n",
    "    f, axarr = plt.subplots(axis[0], axis[1], figsize=(30/axis[1], 10))\n",
    "    index = 0\n",
    "    for i in range(0,axis[0]):\n",
    "        for j in range (0,axis[1]):\n",
    "            # Plot\n",
    "            axarr[i,j].imshow(images[index])\n",
    "            index += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdbbb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See Example of image datagenerator\n",
    "example = image_gen_train.flow_from_dataframe(dataframe=validation,\n",
    "                                                    directory=images_folder_train,\n",
    "                                                    x_col='image_name',\n",
    "                                                    y_col=list_tags,\n",
    "                                                    batch_size=batch_size, #16,32,64...\n",
    "                                                    seed=1,\n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode=\"raw\",\n",
    "                                                    target_size=(width,width))\n",
    "\n",
    "images, _ = next(example)\n",
    "example_images = images[:9]\n",
    "plot_images_datagen(axis=(3,3), images=example_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d6e6fb",
   "metadata": {},
   "source": [
    "# Create Model\n",
    "* <a href=\"https://arxiv.org/abs/1512.03385\">Resnet </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d931b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if GPU is aviable\n",
    "import tensorflow as tf\n",
    "\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da98b825",
   "metadata": {},
   "source": [
    "# Resnet50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f050a0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import applications\n",
    "\n",
    "# See model\n",
    "applications.resnet50.ResNet50(weights= None).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3e0491",
   "metadata": {},
   "source": [
    "# Create model with Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f053b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Op 1:\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "outs = len(list_tags)\n",
    "def ResnetModel(outs = outs, freeze = False, pretrained = False):\n",
    "    \n",
    "    if pretrained:\n",
    "        model_weights = 'imagenet'\n",
    "    else:\n",
    "        model_weights = None\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(applications.resnet50.ResNet50(weights= None, include_top=False, input_shape=(width,width,3)))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(outs, activation= 'sigmoid'))\n",
    "\n",
    "\n",
    "    if freeze:\n",
    "        # Training only top layers i.e. the layers which we have added in the end\n",
    "        # Indicate whether the first layer should be trained/changed or not.\n",
    "        model.layers[0].trainable = False  \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e18e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = ResnetModel(outs = outs, freeze = False, pretrained = False)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ce68c1",
   "metadata": {},
   "source": [
    "# Create model with Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e4f0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Op 2:\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, n_outputs=outs, pretrained=False, freeze=False, size = width, depth = 3):\n",
    "        \n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "           \n",
    "        if pretrained:\n",
    "            self.model_weights = 'imagenet'\n",
    "        else:\n",
    "            self.model_weights = None\n",
    "        \n",
    "        # Download the architecture of ResNet50 with ImageNet weights\n",
    "        self.resnet = applications.resnet50.ResNet50(include_top=False, weights=self.model_weights, input_shape= (width,width, depth))\n",
    "        \n",
    "        # Taking the output of the last convolution block in ResNet50\n",
    "        self.res_out = self.resnet.output\n",
    "        self.res_in = self.resnet.input\n",
    "        \n",
    "        self.GlobPoll = GlobalAveragePooling2D()\n",
    "        \n",
    "        # Adding a fully connected layer having 1024 neurons\n",
    "        #self.fc1 = Dense(1024, activation='relu')\n",
    "        \n",
    "        # Sigmoid Out\n",
    "        self.out = Dense(outs, activation='sigmoid')\n",
    "        \n",
    "        if freeze:\n",
    "            # Training only top layers i.e. the layers which we have added in the end\n",
    "            self.resnet.trainable = False\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        x = self.resnet(inputs)\n",
    "        x = self.GlobPoll(x)\n",
    "        #x = self.fc1(x)\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9938d2",
   "metadata": {},
   "source": [
    "# Instance of Model with default values (No pretrain, No Freeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614bc5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "model = MyModel()\n",
    "#model.build(input_shape=(None,256, 256, 3))\n",
    "#model.summary()\n",
    "#model.layers[0].trainable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e923bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.seed(1)\n",
    "#tf.random.set_seed(1234)\n",
    "\n",
    "#model = ResnetModel()\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93afde55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = MyModel()\n",
    "#model.load_weights(PATH + 'Models/ModelResnet50_Epoch10/Resnet50_tf_batch32_NoPretrained_epoch10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84afc04",
   "metadata": {},
   "source": [
    "# Calculate wights for unbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf07256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_weights = {}\n",
    "negative_weights = {}\n",
    "for c in list_tags:\n",
    "    positive_weights[c] = train.shape[0]/(2*np.count_nonzero(train[c]==1))\n",
    "    negative_weights[c] = train.shape[0]/(2*np.count_nonzero(train[c]==0))\n",
    "print(positive_weights)\n",
    "print('----------------------')\n",
    "print(negative_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d1f701",
   "metadata": {},
   "source": [
    "# Custom loss for unbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e59d13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custon Binary Crossentropy\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def loss_fn(y_true,y_pred):\n",
    "    \n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    \n",
    "    #print(y_true.dtype)\n",
    "    #print(y_pred.dtype)\n",
    "    loss = 0\n",
    "    loss -= (positive_weights['agriculture']*y_true[0]*K.log(y_pred[0]) + negative_weights['agriculture']*(1-y_true[0])*K.log(1-y_pred[0]))\n",
    "    loss -= (positive_weights['bare_ground']*y_true[1]*K.log(y_pred[1]) + negative_weights['bare_ground']*(1-y_true[1])*K.log(1-y_pred[1]))\n",
    "    loss -= (positive_weights['cultivation']*y_true[2]*K.log(y_pred[2]) + negative_weights['cultivation']*(1-y_true[2])*K.log(1-y_pred[2]))\n",
    "    loss -= (positive_weights['habitation']*y_true[3]*K.log(y_pred[3]) + negative_weights['habitation']*(1-y_true[3])*K.log(1-y_pred[3]))\n",
    "    loss -= (positive_weights['primary']*y_true[4]*K.log(y_pred[4]) + negative_weights['primary']*(1-y_true[4])*K.log(1-y_pred[4]))\n",
    "    loss -= (positive_weights['road']*y_true[5]*K.log(y_pred[5]) + negative_weights['road']*(1-y_true[5])*K.log(1-y_pred[5]))\n",
    "    loss -= (positive_weights['water']*y_true[6]*K.log(y_pred[6]) + negative_weights['water']*(1-y_true[6])*K.log(1-y_pred[6]))\n",
    "    #print(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29794a5b",
   "metadata": {},
   "source": [
    "# Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5056e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['categorical_accuracy','accuracy'])\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(0.000003), loss = loss_fn, metrics = ['categorical_accuracy','accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82676b7f",
   "metadata": {},
   "source": [
    "# Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f742f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# EarlyStopping:\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=8, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "STEP_SIZE_TRAIN = train_datagen.n//train_datagen.batch_size\n",
    "STEP_SIZE_VALID = valid_datagen.n//valid_datagen.batch_size\n",
    "STEP_SIZE_TEST = test_datagen.n//test_datagen.batch_size\n",
    "\n",
    "\n",
    "\n",
    "# https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/keras/Model#fit\n",
    "model.fit(x = train_datagen,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_datagen,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=50,\n",
    "                    callbacks=[monitor]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94af2c7",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "96456222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidrestrepo/opt/anaconda3/envs/SeguridadAlimentaria_GPU/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n",
      "2021-08-17 19:21:09.486652: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 143s 592ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict \n",
    "#test_datagen.reset()\n",
    "pred=model.predict_generator(test_datagen,\n",
    "                            steps=STEP_SIZE_TEST,\n",
    "                            verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0515dceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the predictions are: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.20797792, 0.00884381, 0.00669419, ..., 0.99647415, 0.05373644,\n",
       "        0.2459486 ],\n",
       "       [0.88146424, 0.04914488, 0.42343295, ..., 0.9932893 , 0.90127724,\n",
       "        0.3021252 ],\n",
       "       [0.6144184 , 0.03072709, 0.2935545 , ..., 0.99463344, 0.47456154,\n",
       "        0.44160753],\n",
       "       ...,\n",
       "       [0.05268625, 0.00322772, 0.06081653, ..., 0.99970114, 0.0211084 ,\n",
       "        0.06431799],\n",
       "       [0.07344229, 0.00563491, 0.06689786, ..., 0.9996643 , 0.0302663 ,\n",
       "        0.05437705],\n",
       "       [0.08712693, 0.02146338, 0.09976102, ..., 0.97777236, 0.0429875 ,\n",
       "        0.23085521]], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('the predictions are: ')\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3a983546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the predictions are: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [1., 0., 0., ..., 1., 1., 0.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('the predictions are: ')\n",
    "# Transform predictions to 0 or 1\n",
    "round_pred = np.rint(pred)\n",
    "round_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "80212b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the actual values are: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 1, 1, 0],\n",
       "       [1, 0, 0, ..., 1, 1, 1],\n",
       "       [1, 0, 1, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('the actual values are: ')\n",
    "y_true = test_datagen.labels\n",
    "y_true[:round_pred.shape[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3f14ca50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agriculture',\n",
       " 'bare_ground',\n",
       " 'cultivation',\n",
       " 'habitation',\n",
       " 'primary',\n",
       " 'road',\n",
       " 'water']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tags\n",
    "list_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a7ad3821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def get_metrics(y_true=y_true, round_pred=round_pred, column=0):\n",
    "\n",
    "    print(f'The column is {list_tags[column]}')\n",
    "    y_true = y_true[:round_pred.shape[0],column]\n",
    "    round_pred = round_pred[:,column]\n",
    "    \n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = accuracy_score(y_true, round_pred)\n",
    "    print('Accuracy: %f' % accuracy)\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(y_true, round_pred)\n",
    "    print('Precision: %f' % precision)\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(y_true, round_pred)\n",
    "    print('Recall: %f' % recall)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(y_true, round_pred)\n",
    "    print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1c8a1e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "The column is agriculture\n",
      "Accuracy: 0.798379\n",
      "Precision: 0.699911\n",
      "Recall: 0.644262\n",
      "F1 score: 0.670935\n",
      "---------\n",
      "---------\n",
      "The column is bare_ground\n",
      "Accuracy: 0.979341\n",
      "Precision: 0.416667\n",
      "Recall: 0.032051\n",
      "F1 score: 0.059524\n",
      "---------\n",
      "---------\n",
      "The column is cultivation\n",
      "Accuracy: 0.885722\n",
      "Precision: 0.000000\n",
      "Recall: 0.000000\n",
      "F1 score: 0.000000\n",
      "---------\n",
      "---------\n",
      "The column is habitation\n",
      "Accuracy: 0.913964\n",
      "Precision: 0.634454\n",
      "Recall: 0.209141\n",
      "F1 score: 0.314583\n",
      "---------\n",
      "---------\n",
      "The column is primary\n",
      "Accuracy: 0.976857\n",
      "Precision: 0.979619\n",
      "Recall: 0.997056\n",
      "F1 score: 0.988260\n",
      "---------\n",
      "---------\n",
      "The column is road\n",
      "Accuracy: 0.831851\n",
      "Precision: 0.611225\n",
      "Recall: 0.554314\n",
      "F1 score: 0.581380\n",
      "---------\n",
      "---------\n",
      "The column is water\n",
      "Accuracy: 0.822306\n",
      "Precision: 0.608156\n",
      "Recall: 0.231600\n",
      "F1 score: 0.335452\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidrestrepo/opt/anaconda3/envs/SeguridadAlimentaria_GPU/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(list_tags)):\n",
    "    print('---------')\n",
    "    get_metrics(y_true, round_pred, i)\n",
    "    print('---------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568d9e41",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "68834c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights (Class)\n",
    "model.save_weights(PATH + 'Models/ModelResnet50Balanced/Resnet50_tf_batch32_NoPretrained_epoch50')\n",
    "#model.save_weights(PATH + 'Models/ModelResnet50Balanced/Resnet50_tf_batch32_NoPretrained_epoch10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aa325349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model (function)\n",
    "#model.save(PATH + 'Models/Resnet50_tf_batch32_NoPretrained.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba03148",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2086545d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2f925ed00>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load moMyModelModelModell class\n",
    "model2 = MyModel()\n",
    "model2.load_weights(PATH+'Models/ModelResnet50Balanced/Resnet50_tf_batch32_NoPretrained')\n",
    "#model2.load_weights(PATH+'Models/ModelResnet50_Epoch10/Resnet50_tf_batch32_NoPretrained_epoch10')\n",
    "\n",
    "#from tensorflow.keras.models import load_model\n",
    "# Load Model (function) \n",
    "#new_model = load_model(PATH + 'Models/ModelVGG16/VGG16_tf_batch32_NoPretrained.h5')\n",
    "#new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e309653",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f2c0f6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10148496, 0.0047991 , 0.00148913, 0.9999881 , 0.5797755 ,\n",
       "        0.999156  , 0.02957684]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random = np.random.uniform(low=0.0, high=1.0, size=(1,256,256,3))\n",
    "model.predict(random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a34501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el Modelo\n",
    "#model.save(PATH + 'Models/Resnet50_tf_batch32_NoPretrained.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65535322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "e091b0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 8, 8, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 7)                 14343     \n",
      "=================================================================\n",
      "Total params: 23,602,055\n",
      "Trainable params: 23,548,935\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "1d17334a",
   "metadata": {},
   "outputs": [],
   "source": [
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652ed0fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22abdac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb4d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc203b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d96f8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
